# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16i2HWNh2AxDANVwc2hJ2bxbEMJxKUubs

**Data collection(Getting data from kaggle)**
"""

! pip install kaggle

from google.colab import drive
drive.mount('/content/drive')

! mkdir ~/.kaggle

! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d mlg-ulb/creditcardfraud

! unzip creditcardfraud.zip

"""**Getting information about the data**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('/content/creditcard.csv')

data.head()

data.tail()

data.shape

data.info()

data['Class'].value_counts()

data.describe()

"""**Visualization**"""

plt.figure(figsize=(8, 6))
plt.hist(data['Class'],  bins=30,edgecolor='black')
plt.title('Distribution of Class')
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.show()

fraud = data[data['Class'] == 1]
non_fraud = data[data['Class'] == 0]

# Step 3: Plot the distribution of the 'Amount' feature for fraudulent transactions
plt.figure(figsize=(10, 6))

# Using seaborn to plot
sns.histplot(fraud['Amount'], bins=50, kde=True, color='red', label='Fraudulent Transactions', alpha=0.6)


# Set plot title and labels
plt.title('Distribution of Transaction Amounts for Fraudulent ')
plt.xlabel('Transaction Amount')
plt.ylabel('Frequency')
plt.legend()

# Display the plot
plt.show()

# Step 3: Plot the distribution of the 'Amount' feature for non fraudulent transactions
plt.figure(figsize=(10, 6))

sns.histplot(non_fraud['Amount'], bins=50, kde=True, color='blue', label='Non-Fraudulent Transactions', alpha=0.6)

# Set plot title and labels
plt.title('Distribution of Transaction Amounts for non_Fraudulent ')
plt.xlabel('Transaction Amount')
plt.ylabel('Frequency')
plt.legend()

# Display the plot
plt.show()

#Boxplot of the fruadant Amount transactions to see outliers
plt.figure(figsize=(8, 6))
plt.boxplot(fraud['Amount'])
plt.title('Boxplot of the fruadant Amount transactions')
plt.ylabel('fraud Amount')
plt.show()

#Boxplot of the non_fruadant Amount transactions to see outliers
plt.figure(figsize=(8, 6))
plt.boxplot(non_fraud['Amount'])
plt.title('Boxplot of the non_fruadant Amount transactions')
plt.ylabel('non_fraud Amount')
plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(data['Amount'], data['Class'], alpha=0.5)

plt.title('Amount vs. Class')
plt.xlabel('Amount')
plt.ylabel('Class')
plt.show()

"""**Detecting outliers using isolation forest algorithm**"""

from sklearn.ensemble import IsolationForest

# Initialize the Isolation Forest model
iso_forest = IsolationForest(contamination=0.01, random_state=42)

# Fit the model to the dataset (using PCA-transformed features or other numerical features)
outlier_labels = iso_forest.fit_predict(data)  # Example with PCA features

# Add the outlier labels to the DataFrame
data['outlier'] = outlier_labels

# Display the outliers (where outlier == -1)
outliers = data[data['outlier'] == -1]
print(outliers)

data['outlier'].value_counts()

# Find the number of frauds that are outliers
fraud_outliers = data[(data['Class'] == 1) & (data['outlier'] == -1)]['Class'].count()

# Find the number of non-frauds that are not outliers
non_fraud_not_outliers = data[(data['Class'] == 0) & (data['outlier'] == 1)]['Class'].count()

print(f"Number of frauds that are outliers: {fraud_outliers}")
print(f"Number of non-frauds that are not outliers: {non_fraud_not_outliers}")

"""**Drop certain outliers**"""

# Drop rows where 'outlier' is True and 'class' is 0
data.drop(data[(data['outlier'] == -1) & (data['Class'] == 0)].index, inplace=True)
data.shape

"""**some visualization after dropping outliers**"""

plt.figure(figsize=(8, 6))
for i in range(len(data.columns)):
    plt.hist(data.iloc[:, i])
    plt.title(f'Histogram of {data.columns[i]}')
    plt.xlabel(data.columns[i])
    plt.ylabel('Frequency')
    plt.show()

import seaborn as sns
# Plotting a heatmap of the correlation between numerical features
plt.figure(figsize=(20, 18))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

"""**Drop time and outlier columns**"""

data.drop(['Time','outlier'], axis=1, inplace=True)

"""**Data scaling**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
data[['Amount']] = scaler.fit_transform(data[['Amount']])

# prompt: i want to scale the amount column with robust scaler

from sklearn.preprocessing import RobustScaler

# Initialize the RobustScaler
robust_scaler = RobustScaler()

# Fit and transform the 'Amount' column
data[['Amount']] = robust_scaler.fit_transform(data[['Amount']])

data.head()

"""**Handling the unbalance using SMOTE algoritm (oversampling)**"""

x = data.drop('Class', axis=1)
y = data['Class']

from imblearn.over_sampling import SMOTE
from collections import Counter

# Initialize SMOTE
smote = SMOTE(sampling_strategy=.3, random_state=42)

# Apply SMOTE to the training data
X_resampled, y_resampled = smote.fit_resample(x, y)

y_resampled.value_counts()

X_resampled.tail()

X_resampled.shape

"""**Buliding different models with different evaluation metrics**"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, roc_auc_score, accuracy_score
from sklearn.metrics import precision_recall_curve, roc_curve, auc

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)

"""**Logitic Regression**"""

model_logist = LogisticRegression()
model_logist.fit(X_train, y_train)
y_pred_logist = model_logist.predict(X_test)
print(classification_report(y_test, y_pred_logist))

print(roc_auc_score(y_test, y_pred_logist)*100)
print(accuracy_score(y_test, y_pred_logist)*100)

"""**Support vector machine**"""

model_svm = SVC()
model_svm.fit(X_train, y_train)
y_pred_svm = model_svm.predict(X_test)
print(classification_report(y_test, y_pred_svm))

print(roc_auc_score(y_test, y_pred_svm)*100)
print(accuracy_score(y_test, y_pred_svm)*100)

"""**Random Forest**"""

model_rf = RandomForestClassifier()
model_rf.fit(X_train, y_train)
y_pred_rf = model_rf.predict(X_test)
print(classification_report(y_test, y_pred_rf))
print(roc_auc_score(y_test, y_pred_rf))
print(accuracy_score(y_test, y_pred_rf))

print(roc_auc_score(y_test, y_pred_rf)*100)
print(accuracy_score(y_test, y_pred_rf)*100)

"""**Testing the logistic regression model**"""

# Randomly select one row from X_test
X_test_fraud_random = X_test[y_test == 1].sample(1, random_state=42)

# Get the index of the selected row
row_index = X_test_fraud_random.index[0]

# Retrieve the corresponding label from y_test using the index
fraud_label = y_test.loc[row_index]

# Display the label
print(f"The label of the selected row is: {fraud_label}")

p = model_logist.predict(X_test_fraud_random.values.reshape(1, -1))
print(p)

"""**Testing the SVM model**"""

p_2 = model_svm.predict(X_test_fraud_random.values.reshape(1, -1))
print(p_2)

"""**Testing the Random forest model**"""

p_3 = model_rf.predict(X_test_fraud_random.values.reshape(1, -1))
print(p_3)

